{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "CatsVSDogs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBos5RDoCQli",
        "colab_type": "text"
      },
      "source": [
        "## Cats vs Dogs Classification\n",
        "\n",
        "This notebook uses a neural network to classify cats and dogs based on the images.\n",
        "\n",
        "Following are the imports required for the project. Tqdm is used to bring out the progress bar when used in a loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1fifZ7nn7s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5vA1UbzEdWY",
        "colab_type": "text"
      },
      "source": [
        "ZipFile uses extractall function to extract images compressed as a zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IyUl-vMgcoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"PetImages.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvMrnxdVEs1V",
        "colab_type": "text"
      },
      "source": [
        "The path of cats and dogs are provided and cats is labelled as 0 and dogs as 1. Initializing count of both to 0. \n",
        "\n",
        "builddata function is used to form data by converting the images into array of integers. Each image is rescaled to 50*50 pixels since all images have to be of same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl4oRTTDn7s8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_path = \"PetImages/Cat\"\n",
        "dog_path = \"PetImages/Dog\"\n",
        "img_size = 50\n",
        "labels = {cat_path:0,dog_path:1}\n",
        "cat_count = 0\n",
        "dog_count = 0\n",
        "data = []\n",
        "BUILD = True\n",
        "    \n",
        "def builddata():\n",
        "    cat_count = 0\n",
        "    dog_count = 0\n",
        "    for i in labels:\n",
        "        for j in tqdm(os.listdir(i)):\n",
        "            try:\n",
        "                img = cv2.imread(os.path.join(i,j),cv2.IMREAD_GRAYSCALE)\n",
        "                img = cv2.resize(img,(img_size,img_size))\n",
        "                data.append([np.array(img),np.eye(2)[labels[i]]])\n",
        "                if(i == cat_path):\n",
        "                    cat_count += 1\n",
        "                else:\n",
        "                    dog_count += 1\n",
        "            except Exception as e:\n",
        "                pass\n",
        "    np.random.shuffle(data)\n",
        "    np.save(\"catsvsdogs.npy\",data)\n",
        "    print(f\"Dogs : {dog_count} , Cats : {cat_count}\")\n",
        "\n",
        "if BUILD:\n",
        "    builddata()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "820KNQPDOn-B",
        "colab_type": "text"
      },
      "source": [
        "Loading the numpy object from saved data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQe4NwFPn7tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.load(\"catsvsdogs.npy\",allow_pickle=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpC4byc2Oulo",
        "colab_type": "text"
      },
      "source": [
        "Plotting one image in gray scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Bh_V-Ln7tD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "0fd7d47d-1ec6-4304-c077-2ef3d6242384"
      },
      "source": [
        "\n",
        "img = cv2.imread(\"PetImages/Cat/0.jpg\",cv2.IMREAD_GRAYSCALE)\n",
        "print(img.shape)\n",
        "img = cv2.resize(img,(50,50))\n",
        "print(img.shape)\n",
        "\n",
        "plt.imshow(np.array(img))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(375, 500)\n",
            "(50, 50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff6c080a630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uec9p0kMO1s1",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "The model is built here with 3 dense layers of convolution 2d. The first layer takes in 1 input and produces 32 dimensions of second layer takes in 32D and produces 64D and third layer of input 64D and output 128D. Each layers with 5*5 filters.\n",
        "\n",
        "We do not know the number of features into the Linear layer which is kind of flattening the model. Thus it is calculated by passing one image and finding out the self.to_linear which gives the shape as input to linear layer.\n",
        "\n",
        "Two fully connected layers are formed with 1st one taking input of self.to_linear and output of 512 and second one with input 512 and output 2 which are our classes of cats and dogs.\n",
        "\n",
        "In the model , we are using relu as activation function and max pool 2D with 2*2  as the pooling layer.\n",
        "\n",
        "The output is formed as the softmax layer outputing the maximum value of the predicted classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jRzaiMdn7tF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXiKdcEcn7tH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c7bf2933-1a24-4560-dcd0-7296f86e11d1"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cv1 = nn.Conv2d(1,32,5)\n",
        "        self.cv2 = nn.Conv2d(32,64,5)\n",
        "        self.cv3 = nn.Conv2d(64,128,5)\n",
        "        \n",
        "        self.to_linear = None\n",
        "        x = torch.randn(50,50).view(-1,1,50,50)\n",
        "        self.convs(x)\n",
        "        \n",
        "        self.fc1 = nn.Linear(self.to_linear,512)\n",
        "        self.fc2 = nn.Linear(512,2)\n",
        "    \n",
        "    def convs(self,x):\n",
        "        x = F.max_pool2d(F.relu(self.cv1(x)),(2,2))\n",
        "        x = F.max_pool2d(F.relu(self.cv2(x)),(2,2))\n",
        "        x = F.max_pool2d(F.relu(self.cv3(x)),(2,2))\n",
        "        \n",
        "        if self.to_linear is None:\n",
        "            print(x.shape, x[0].shape)\n",
        "            self.to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1,self.to_linear)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x,dim=1)\n",
        "        \n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 128, 2, 2]) torch.Size([128, 2, 2])\n",
            "Net(\n",
            "  (cv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (cv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (cv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYNjC2-RUJhb",
        "colab_type": "text"
      },
      "source": [
        "The model is trained using an Adam optimizer and MSE is used in loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI-eMgBvn7tK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss = nn.MSELoss()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGH79x03UU44",
        "colab_type": "text"
      },
      "source": [
        "Next, features and labels are formed. Validation of 10% data is used for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRWYC19Wn7tO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.Tensor([i[0] for i in data]).view(-1,50,50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in data])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DePY_0X2n7tQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_size = 0.1\n",
        "val_data = int(val_size * (len(data)))\n",
        "train_X = X[:-val_data]\n",
        "train_y = y[:-val_data]\n",
        "\n",
        "test_X = X[-val_data:]\n",
        "test_y = y[-val_data:]\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFker5Dln7tS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_X),len(test_X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdi1H6eqUgWG",
        "colab_type": "text"
      },
      "source": [
        "For each epochs, the data is given in batches to the model and is trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r59hJzXwn7tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH = 10\n",
        "EPOCHS = 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for i in tqdm(range(0,len(train_X),BATCH)):\n",
        "        x = train_X[i:i+BATCH].view(-1,1,50,50)\n",
        "        y = train_y[i:i+BATCH]\n",
        "        \n",
        "        output = net(x)\n",
        "        loss_val = loss(output,y)\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    print(f\"Epoch : {epoch} , Loss : {loss_val}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flms1ihuUonb",
        "colab_type": "text"
      },
      "source": [
        "The test data is used in testing and accuracy is found out using this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lecIehZkn7tW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73e45627-9b1a-4532-ff37-0c102e4c1e19"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for i in tqdm(range(len(test_X))):\n",
        "  actual = torch.argmax(test_y[i])\n",
        "  preds = net(test_X[i].view(-1,1,50,50))[0]\n",
        "  pred_val = torch.argmax(preds)\n",
        "  if pred_val == actual:\n",
        "    correct += 1\n",
        "  total += 1\n",
        "print(\"Accuracy : \",(correct/total)*100,\"%\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2494/2494 [00:05<00:00, 426.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  54.04971932638332 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U3Ku_7-lEeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Here, we got an accuracy of 54% . It could be improved by tuning parameters and increasing more dense layers."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}